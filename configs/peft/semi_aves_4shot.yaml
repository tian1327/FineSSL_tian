# === Dataset & Backbone ===
dataset: "semi-aves"
backbone: "vitb32_openclip_laion400m"
resolution: 224
stride: 32

# === Output ===
output_dir: "out/semi-aves/N4"
checkpoint_freq: 0
print_freq: 10

# === Training Settings ===
num_epochs: 30
lr: 0.03
weight_decay: 5e-4
momentum: 0.9
num_workers: 8
prec: "fp16"  # or "amp" if you're using PyTorch AMP

# === Prompt Template ===
template: "a photo of a {}."

# === Data Settings ===
DATA:
  SHOTS: 4             # few-shot shots per class
  SEED: 1              # seed for sampling few-shot subset
  NUMBER_CLASSES: 200  # number of classes in Semi-Aves
  BATCH_SIZE: 32
  MU_U: 1              # unlabeled to labeled batch ratio
  IMB_L: 1.0           # imbalance ratio for labeled data (not used here)
  IMB_U: 1.0           # imbalance ratio for unlabeled data (not used here)

# === Modular Tuning ===
finetune: False
bias_tuning: False
vpt_shallow: False
vpt_deep: True
vpt_last: False
vpt_len: 50
adapter: False
lora: False
ssf: False

# === FixMatch Specific ===
th: 0.7        # confidence threshold for pseudo-labeling
mode: 0        # augmentation mode (0 = FixMatch)
alpha: 8.0     # balancing factor between CE and consistency loss
w_con: 3.0     # weight for consistency loss
smoothing: 0.5 # label smoothing for CE loss
