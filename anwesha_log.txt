1. In datasets/data.py :
    
    a. In the function get_semi_aves(), 
        Originally,they were using the imagenet mean and std deviation. 
        # dataset_mean = (0.485, 0.456, 0.406)
        # dataset_std = (0.229, 0.224, 0.225)

        I replaced it with the values we were using for openclip in our SSL codebase.
        dataset_mean=(0.48145466, 0.4578275, 0.40821073),
        dataset_std=(0.26862954, 0.26130258, 0.27577711)
    
    b. Added CustomFewShotDataset	
        This generalizes loading from .txt files (few-shot, unlabeled, test).

    c. We are still using the original augmentation strategy (RandAugment, weak/strong split).

    d. In the function get_semi_aves(),
    	we integrate both the updated dataset reader and the unchanged transformation logic.


2. In trainer.py : 
    a. Added function load_classnames_from_metrics(dataset_name, num_classes) for loading classnames from the JSON metrics file.
        It extracts "most_common_name" from the correct JSON.

    b. In the Trainer class's __init__() function:
        We add clip_model, tokenizer args.
        We Load and assign self.classnames.

    c. In the Trainer class's build_model() function:
        We use self.clip_model, self.tokenizer instead of load_clip_to_cpu and clip.tokenize.
        we update the logic to tokenize prompts and encode texts, assuming OpenCLIP tokenizer and model.


3. In main.py :
    We replace the trainer = Trainer(cfg) line with New logic for open_clip.

4. We add new config files for few shot 

5. Run : python main.py --cfg configs/semi_aves_4shot.yaml
    
